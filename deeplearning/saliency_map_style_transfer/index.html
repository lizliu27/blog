<!doctype html><html dir=ltr lang=en data-theme class="html theme--light"><head><meta charset=utf-8><title>Liz Liu
|
Saliency Maps, GradCAM and Style Transfer
</title><meta name=generator content="Hugo 0.125.5"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Liz Liu"><meta name=description content="Machine Learning & Life
"><link rel=stylesheet href=/blog/scss/main.min.009f917038f30ebd1f2147e8e1dfd40fc1b799422a7869aa0da12af1fd1bf8ba.css integrity="sha256-AJ+RcDjzDr0fIUfo4d/UD8G3mUIqeGmqDaEq8f0b+Lo=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/blog/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/blog/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=canonical href=https://lizliu27.github.io/blog/deeplearning/saliency_map_style_transfer/><script type=text/javascript src=/blog/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script><script type=text/javascript src=/blog/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Saliency Maps, GradCAM and Style Transfer"><meta name=twitter:description content="Project 3: Implementing various techniques related to image analysis and manipulation using deep learning Specifically convolutional neural networks (CNNs) and style transfer. Here&rsquo;s a summary of the tasks and techniques covered:
Class Model Visualizations: Synthesizing images to maximize classification scores for specific classes, providing insights into network focus during classification. Generating class-specific saliency maps to understand image areas influencing classification decisions. Creating fooling images by perturbing input images to mislead pretrained networks."><meta property="og:url" content="https://lizliu27.github.io/blog/deeplearning/saliency_map_style_transfer/"><meta property="og:site_name" content="Liz Blog"><meta property="og:title" content="Saliency Maps, GradCAM and Style Transfer"><meta property="og:description" content="Project 3: Implementing various techniques related to image analysis and manipulation using deep learning Specifically convolutional neural networks (CNNs) and style transfer. Hereâ€™s a summary of the tasks and techniques covered:
Class Model Visualizations: Synthesizing images to maximize classification scores for specific classes, providing insights into network focus during classification. Generating class-specific saliency maps to understand image areas influencing classification decisions. Creating fooling images by perturbing input images to mislead pretrained networks."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="deeplearning"><meta property="article:published_time" content="2023-11-28T11:22:17+08:00"><meta property="article:modified_time" content="2023-11-28T11:22:17+08:00"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"deeplearning","name":"Saliency Maps, GradCAM and Style Transfer","headline":"Saliency Maps, GradCAM and Style Transfer","alternativeHeadline":"","description":"
      
        Project 3: Implementing various techniques related to image analysis and manipulation using deep learning Specifically convolutional neural networks (CNNs) and style transfer. Here\u0026rsquo;s a summary of the tasks and techniques covered:\nClass Model Visualizations: Synthesizing images to maximize classification scores for specific classes, providing insights into network focus during classification. Generating class-specific saliency maps to understand image areas influencing classification decisions. Creating fooling images by perturbing input images to mislead pretrained networks.


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/lizliu27.github.io\/blog\/deeplearning\/saliency_map_style_transfer\/"},"author":{"@type":"Person","name":"Liz Liu"},"creator":{"@type":"Person","name":"Liz Liu"},"accountablePerson":{"@type":"Person","name":"Liz Liu"},"copyrightHolder":{"@type":"Person","name":"Liz Liu"},"copyrightYear":"2023","dateCreated":"2023-11-28T11:22:17.00Z","datePublished":"2023-11-28T11:22:17.00Z","dateModified":"2023-11-28T11:22:17.00Z","publisher":{"@type":"Organization","name":"Liz Liu","url":"https://lizliu27.github.io/blog/","logo":{"@type":"ImageObject","url":"https:\/\/lizliu27.github.io\/blog\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/lizliu27.github.io\/blog\/deeplearning\/saliency_map_style_transfer\/","wordCount":"491","genre":[],"keywords":[]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/blog/images/avatar.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/blog>Liz Blog</a></div><div class=sidebar__introduction-description><p>Machine Learning & Life<br></p></div></div><ul class=sidebar__list></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Liz Liu
2024</li></ul></footer><script type=text/javascript src=/blog/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/blog/ title>Home</a></li><li class=nav__list-item><a href=/blog/machinelearning/ title>Machine Learning for Trading</a></li><li class=nav__list-item><a href=/blog/about/ title>About</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Saliency Maps, GradCAM and Style Transfer</h1><h2 id=project-3-implementing-various-techniques-related-to-image-analysis-and-manipulation-using-deep-learning>Project 3: Implementing various techniques related to image analysis and manipulation using deep learning</h2><p>Specifically convolutional neural networks (CNNs) and style transfer.
Here&rsquo;s a summary of the tasks and techniques covered:</p><h3 id=class-model-visualizations>Class Model Visualizations:</h3><ul><li>Synthesizing images to maximize classification scores for specific classes, providing insights into network focus during classification.</li><li>Generating class-specific saliency maps to understand image areas influencing classification decisions.</li><li>Creating fooling images by perturbing input images to mislead pretrained networks.</li></ul><h3 id=gradient-class-activation-mapping-gradcam>Gradient Class Activation Mapping (GradCAM):</h3><ul><li>Implementing guided backpropagation and GradCAM techniques to visualize areas of an image relevant to specific class labels.</li><li>Utilizing Captum to implement GradCAM and visualize relevant image areas.</li></ul><h3 id=adversarial-examples>Adversarial Examples:</h3><ul><li>Generating fooling images by performing gradient ascent on input images to maximize classification for specific target classes.</li></ul><h2 id=summary-of-saliency-maps-and-gradcam>Summary of Saliency Maps and GradCAM</h2><p>Saliency Maps provide visualization of image regions contributing most to the CNN&rsquo;s decision. They are determined by computing gradients with respect to input pixels, where high gradient magnitudes indicate strong impact on the model&rsquo;s output. Saliency maps are suitable for general interpretability and providing quick overviews of attention regions.</p><p>On the other hand, GradCAM (Gradient-weighted Class Activation Mapping) is designed for class-specific localization information. It highlights regions highly relevant to a specific class by combining information from multiple layers and inspecting gradients of output class scores with respect to intermediate layers. GradCAM is particularly valuable for understanding why the model made certain predictions, especially in object detection tasks. However, it requires access to model layers and is more involved to implement.</p><p>In practice, both methods have strengths and can be used in combination. Saliency maps provide quick insights into overall attention regions, while GradCAM offers detailed class-specific localization information for a deeper understanding of model decisions.</p><p><img src=/blog/images/gradcam.jpg alt=gradcam></p><h3 id=style-transfer>Style Transfer:</h3><p>Style transfer is a technique that allows us to apply the style of one image to the content of another, resulting in a new image that combines the two. How to do this :) ? We do this by first formulating a loss function that matches the content and style of each respective image in the feature space of a deep network, and then performing gradient
descent on the pixels of the image itself.</p><ul><li>Implementing content loss, style loss, and total variation loss functions for style transfer using convolutional neural networks.</li><li>Stringing together loss functions and update rules to perform style transfer from a style image to a content image.</li><li>Applying style transfer to generate stylized images by combining the content of one image with the style of another.
<img src=/blog/images/style_trans1.jpg alt=style_trans1>
<img src=/blog/images/style_trans2.jpg alt=style_trans2></li></ul><p>The project provided hands-on experience with various techniques for interpreting and manipulating deep neural networks trained on image data. By implementing these techniques, participants gained insights into network behavior, learned methods for generating visually appealing outputs, and explored the nuances of image analysis in the context of deep learning.</p><p>Overall, Project 3 served as a comprehensive exploration of image analysis and manipulation techniques using deep learning, offering practical experience in implementing and understanding these methods.</p></div><div class=post__footer></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Liz Liu
2024</li></ul></footer><script type=text/javascript src=/blog/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></body></html>