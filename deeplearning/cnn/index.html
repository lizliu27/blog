<!doctype html><html dir=ltr lang=en data-theme class="html theme--light"><head><meta charset=utf-8><title>Liz Liu
|
CNN
</title><meta name=generator content="Hugo 0.125.6"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Liz Liu"><meta name=description content="Machine Learning & Life
"><link rel=stylesheet href=/blog/scss/main.min.009f917038f30ebd1f2147e8e1dfd40fc1b799422a7869aa0da12af1fd1bf8ba.css integrity="sha256-AJ+RcDjzDr0fIUfo4d/UD8G3mUIqeGmqDaEq8f0b+Lo=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/blog/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/blog/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/blog/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=canonical href=https://lizliu27.github.io/blog/deeplearning/cnn/><script type=text/javascript src=/blog/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script><script type=text/javascript src=/blog/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="CNN"><meta name=twitter:description content="Project 2: Training Convolutional Neural Network (CNN) from scratch Module Implementation:
I learned to build a two-layer network with fully connected layers and a sigmoid activation function. I implemented a vanilla CNN with a convolutional layer, ReLU activation, max-pooling layer, and fully connected layer for classification. I had the opportunity to design and build my own custom CNN model, adhering to the principles of network architecture design. CNN Model Summary"><meta property="og:url" content="https://lizliu27.github.io/blog/deeplearning/cnn/"><meta property="og:site_name" content="Liz Blog"><meta property="og:title" content="CNN"><meta property="og:description" content="Project 2: Training Convolutional Neural Network (CNN) from scratch Module Implementation:
I learned to build a two-layer network with fully connected layers and a sigmoid activation function. I implemented a vanilla CNN with a convolutional layer, ReLU activation, max-pooling layer, and fully connected layer for classification. I had the opportunity to design and build my own custom CNN model, adhering to the principles of network architecture design. CNN Model Summary"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="deeplearning"><meta property="article:published_time" content="2023-11-28T11:22:17+08:00"><meta property="article:modified_time" content="2023-11-28T11:22:17+08:00"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"deeplearning","name":"CNN","headline":"CNN","alternativeHeadline":"","description":"
      
        Project 2: Training Convolutional Neural Network (CNN) from scratch Module Implementation:\nI learned to build a two-layer network with fully connected layers and a sigmoid activation function. I implemented a vanilla CNN with a convolutional layer, ReLU activation, max-pooling layer, and fully connected layer for classification. I had the opportunity to design and build my own custom CNN model, adhering to the principles of network architecture design. CNN Model Summary


      


    ","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/lizliu27.github.io\/blog\/deeplearning\/cnn\/"},"author":{"@type":"Person","name":"Liz Liu"},"creator":{"@type":"Person","name":"Liz Liu"},"accountablePerson":{"@type":"Person","name":"Liz Liu"},"copyrightHolder":{"@type":"Person","name":"Liz Liu"},"copyrightYear":"2023","dateCreated":"2023-11-28T11:22:17.00Z","datePublished":"2023-11-28T11:22:17.00Z","dateModified":"2023-11-28T11:22:17.00Z","publisher":{"@type":"Organization","name":"Liz Liu","url":"https://lizliu27.github.io/blog/","logo":{"@type":"ImageObject","url":"https:\/\/lizliu27.github.io\/blog\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/lizliu27.github.io\/blog\/deeplearning\/cnn\/","wordCount":"332","genre":[],"keywords":[]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/blog/images/avatar.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/blog>Liz Blog</a></div><div class=sidebar__introduction-description><p>Machine Learning & Life<br></p></div></div><ul class=sidebar__list></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Liz Liu
2024</li></ul></footer><script type=text/javascript src=/blog/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/blog/ title>Home</a></li><li class=nav__list-item><a href=/blog/machinelearning/ title>Machine Learning for Trading</a></li><li class=nav__list-item><a href=/blog/about/ title>About</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>CNN</h1><h2 id=project-2-training-convolutional-neural-network-cnn-from-scratch>Project 2: Training Convolutional Neural Network (CNN) from scratch</h2><ol><li><p><strong>Module Implementation</strong>:</p><ul><li>I learned to build a two-layer network with fully connected layers and a sigmoid activation function.</li><li>I implemented a vanilla CNN with a convolutional layer, ReLU activation, max-pooling layer, and fully connected layer for classification.</li><li>I had the opportunity to design and build my own custom CNN model, adhering to the principles of network architecture design.</li></ul><p>CNN Model Summary</p><p><strong>Model Structure:</strong></p><ul><li>Input: 32x32x3 images</li><li>Convolutional Layers: Two sets of convolutions (each with two 3x3 kernels) followed by ReLU activation and max-pooling, gradually increasing output channels (32, 64, 128, 256).</li><li>Fully Connected Layers: Two FC layers with ReLU activation.</li></ul><p><strong>Hyperparameters:</strong></p><ul><li>Batch Size: 64 (reduced for faster convergence)</li><li>Learning Rate: 0.03 (increased for faster convergence in limited epochs)</li><li>Regularization (reg): 0.0005</li><li>Epochs: 10 (limited)</li><li>Steps: [6, 8] (adjust learning rate during training)</li><li>Warmup: 0.0001 (minimal warmup)</li><li>Momentum: 0.9</li></ul><p><strong>Justification:</strong></p><ul><li>Convolutional Layers: Efficiently capture hierarchical image features.</li><li>ReLU Activation: Introduces non-linearity for better learning.</li><li>Pooling Layers: Reduce dimensionality for faster computation and reduce overfitting.</li><li>Fully Connected Layers: Enable learning of complex decision boundaries.</li></ul><p><strong>Overall:</strong></p><ul><li>Designed for efficient feature extraction from images.</li><li>Carefully chosen hyperparameters for faster convergence and prevention of overfitting within limited epochs.</li></ul><ol start=2><li><strong>Handling Unbalanced Datasets</strong>:</li></ol><ul><li>I explored the challenges posed by unbalanced datasets, where samples of each class are not evenly distributed.</li><li>I experimented with the limitations of standard training strategies on unbalanced datasets using an unbalanced version of CIFAR-10.</li><li>I implemented and evaluated a solution to the imbalance problem using Class-Balanced Focal Loss, as proposed in the CVPR-19 paper.</li></ul><ol start=3><li><strong>Hands-on Experience</strong>:</li></ol><ul><li>Through the implementation of various components of CNNs, I gained practical experience in neural network architecture design and implementation.</li><li>I learned about the importance of experimentation and testing in machine learning projects, especially when dealing with real-world datasets and challenges.</li></ul><p>Overall, this project provided me with valuable insights into CNN architecture, training strategies for handling unbalanced datasets, and the importance of implementing and evaluating novel techniques in machine learning research.</p></li></ol></div><div class=post__footer></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Liz Liu
2024</li></ul></footer><script type=text/javascript src=/blog/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></body></html>